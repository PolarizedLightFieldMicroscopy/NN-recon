{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 32, 16, 16, 16]          13,856\n",
      "              ReLU-2       [-1, 32, 16, 16, 16]               0\n",
      "            Conv3d-3       [-1, 32, 16, 16, 16]          27,680\n",
      "              ReLU-4       [-1, 32, 16, 16, 16]               0\n",
      "            Conv3d-5       [-1, 32, 16, 16, 16]          13,856\n",
      "              ReLU-6       [-1, 32, 16, 16, 16]               0\n",
      "            Conv3d-7       [-1, 32, 16, 16, 16]          27,680\n",
      "              ReLU-8       [-1, 32, 16, 16, 16]               0\n",
      "            Conv3d-9       [-1, 32, 16, 16, 16]          13,856\n",
      "             ReLU-10       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-11       [-1, 32, 16, 16, 16]          27,680\n",
      "             ReLU-12       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-13       [-1, 32, 16, 16, 16]          13,856\n",
      "             ReLU-14       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-15       [-1, 32, 16, 16, 16]          27,680\n",
      "             ReLU-16       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-17       [-1, 32, 16, 16, 16]          13,856\n",
      "             ReLU-18       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-19       [-1, 32, 16, 16, 16]          27,680\n",
      "             ReLU-20       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-21       [-1, 32, 16, 16, 16]          13,856\n",
      "             ReLU-22       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-23       [-1, 32, 16, 16, 16]          27,680\n",
      "             ReLU-24       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-25       [-1, 32, 16, 16, 16]          13,856\n",
      "             ReLU-26       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-27       [-1, 32, 16, 16, 16]          27,680\n",
      "             ReLU-28       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-29       [-1, 32, 16, 16, 16]          13,856\n",
      "             ReLU-30       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-31       [-1, 32, 16, 16, 16]          27,680\n",
      "             ReLU-32       [-1, 32, 16, 16, 16]               0\n",
      "           Conv3d-33      [-1, 128, 16, 16, 16]         221,312\n",
      "             ReLU-34      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-35      [-1, 128, 16, 16, 16]         442,496\n",
      "             ReLU-36      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-37      [-1, 128, 16, 16, 16]         221,312\n",
      "             ReLU-38      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-39      [-1, 128, 16, 16, 16]         442,496\n",
      "             ReLU-40      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-41      [-1, 128, 16, 16, 16]         221,312\n",
      "             ReLU-42      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-43      [-1, 128, 16, 16, 16]         442,496\n",
      "             ReLU-44      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-45      [-1, 128, 16, 16, 16]         221,312\n",
      "             ReLU-46      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-47      [-1, 128, 16, 16, 16]         442,496\n",
      "             ReLU-48      [-1, 128, 16, 16, 16]               0\n",
      "          Flatten-49              [-1, 2097152]               0\n",
      "          Flatten-50               [-1, 524288]               0\n",
      "          Flatten-51               [-1, 524288]               0\n",
      "          Flatten-52               [-1, 524288]               0\n",
      "          Flatten-53               [-1, 524288]               0\n",
      "           Linear-54                  [-1, 128]     536,871,040\n",
      "             ReLU-55                  [-1, 128]               0\n",
      "           Linear-56                   [-1, 64]           8,256\n",
      "             ReLU-57                   [-1, 64]               0\n",
      "           Linear-58                   [-1, 32]           2,080\n",
      "             ReLU-59                   [-1, 32]               0\n",
      "           Linear-60                   [-1, 16]             528\n",
      "             ReLU-61                   [-1, 16]               0\n",
      "           Linear-62                    [-1, 8]             136\n",
      "             ReLU-63                    [-1, 8]               0\n",
      "           Linear-64                    [-1, 3]              27\n",
      "================================================================\n",
      "Total params: 539,869,587\n",
      "Trainable params: 539,869,587\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 128.00\n",
      "Params size (MB): 2059.44\n",
      "Estimated Total Size (MB): 2187.94\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Model_B import B13Net, B13NetV1, UNet\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "input = torch.randn(2, 16, 16, 16, 16)\n",
    "\n",
    "model = B13NetV1(output_size=3).to(device)\n",
    "writer = SummaryWriter(\"runs/Model_B\")\n",
    "print(summary(model, input_size=(2, 16, 16, 16, 16)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 40, 256, 256]             400\n",
      "              ReLU-2         [-1, 40, 256, 256]               0\n",
      "            Conv2d-3         [-1, 40, 256, 256]          14,440\n",
      "              ReLU-4         [-1, 40, 256, 256]               0\n",
      "         MaxPool2d-5         [-1, 40, 128, 128]               0\n",
      "            Conv2d-6         [-1, 80, 128, 128]          28,880\n",
      "              ReLU-7         [-1, 80, 128, 128]               0\n",
      "            Conv2d-8         [-1, 80, 128, 128]          57,680\n",
      "              ReLU-9         [-1, 80, 128, 128]               0\n",
      "        MaxPool2d-10           [-1, 80, 64, 64]               0\n",
      "           Conv2d-11          [-1, 160, 64, 64]         115,360\n",
      "             ReLU-12          [-1, 160, 64, 64]               0\n",
      "           Conv2d-13          [-1, 160, 64, 64]         230,560\n",
      "             ReLU-14          [-1, 160, 64, 64]               0\n",
      "        MaxPool2d-15          [-1, 160, 32, 32]               0\n",
      "           Conv2d-16          [-1, 320, 32, 32]         461,120\n",
      "             ReLU-17          [-1, 320, 32, 32]               0\n",
      "           Conv2d-18          [-1, 320, 32, 32]         921,920\n",
      "             ReLU-19          [-1, 320, 32, 32]               0\n",
      "        MaxPool2d-20          [-1, 320, 16, 16]               0\n",
      "           Conv2d-21          [-1, 640, 16, 16]       1,843,840\n",
      "             ReLU-22          [-1, 640, 16, 16]               0\n",
      "           Conv2d-23          [-1, 640, 16, 16]       3,687,040\n",
      "             ReLU-24          [-1, 640, 16, 16]               0\n",
      "  ConvTranspose2d-25          [-1, 320, 32, 32]         819,520\n",
      "           Conv2d-26          [-1, 320, 32, 32]       1,843,520\n",
      "             ReLU-27          [-1, 320, 32, 32]               0\n",
      "           Conv2d-28          [-1, 320, 32, 32]         921,920\n",
      "             ReLU-29          [-1, 320, 32, 32]               0\n",
      "  ConvTranspose2d-30          [-1, 160, 64, 64]         204,960\n",
      "           Conv2d-31          [-1, 160, 64, 64]         460,960\n",
      "             ReLU-32          [-1, 160, 64, 64]               0\n",
      "           Conv2d-33          [-1, 160, 64, 64]         230,560\n",
      "             ReLU-34          [-1, 160, 64, 64]               0\n",
      "  ConvTranspose2d-35         [-1, 80, 128, 128]          51,280\n",
      "           Conv2d-36         [-1, 80, 128, 128]         115,280\n",
      "             ReLU-37         [-1, 80, 128, 128]               0\n",
      "           Conv2d-38         [-1, 80, 128, 128]          57,680\n",
      "             ReLU-39         [-1, 80, 128, 128]               0\n",
      "  ConvTranspose2d-40         [-1, 40, 256, 256]          12,840\n",
      "           Conv2d-41         [-1, 40, 256, 256]          28,840\n",
      "             ReLU-42         [-1, 40, 256, 256]               0\n",
      "           Conv2d-43         [-1, 40, 256, 256]          14,440\n",
      "             ReLU-44         [-1, 40, 256, 256]               0\n",
      "           Conv2d-45          [-1, 1, 256, 256]              41\n",
      "================================================================\n",
      "Total params: 12,123,081\n",
      "Trainable params: 12,123,081\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 352.38\n",
      "Params size (MB): 46.25\n",
      "Estimated Total Size (MB): 398.87\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = UNet(in_channels=1, out_channels=1, depth=4, feat=40, final_activation=None).to(device)\n",
    "print(summary(model2, input_size=(1, 256, 256)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{140221317902032: 'encoder.0.0.weight', 140221317902272: 'encoder.0.0.bias', 140221317896592: 'encoder.0.2.weight', 140221317895232: 'encoder.0.2.bias', 140221317894032: 'encoder.1.0.weight', 140221317891952: 'encoder.1.0.bias', 140221317890112: 'encoder.1.2.weight', 140221510190640: 'encoder.1.2.bias', 140221355192976: 'encoderB.0.0.weight', 140221319511824: 'encoderB.0.0.bias', 140221317662736: 'encoderB.0.2.weight', 140221317668016: 'encoderB.0.2.bias', 140221317673216: 'encoderB.1.0.weight', 140221317671296: 'encoderB.1.0.bias', 140221317676656: 'encoderB.1.2.weight', 140221317676416: 'encoderB.1.2.bias'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'B13NetV1' object has no attribute 'grad_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m dot\n\u001b[1;32m     55\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m g \u001b[39m=\u001b[39m make_dot(model, model\u001b[39m.\u001b[39;49mstate_dict())\n\u001b[1;32m     57\u001b[0m g\u001b[39m.\u001b[39mview()\n",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m, in \u001b[0;36mmake_dot\u001b[0;34m(var, params)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 dot\u001b[39m.\u001b[39medge(\u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(t)), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(var)))\n\u001b[1;32m     51\u001b[0m                 add_nodes(t)\n\u001b[0;32m---> 52\u001b[0m add_nodes(var\u001b[39m.\u001b[39;49mgrad_fn)\n\u001b[1;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m dot\n",
      "File \u001b[0;32m~/conda/envs/FC/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'B13NetV1' object has no attribute 'grad_fn'"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    \n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    \n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    param_map = {id(v): k for k, v in params.items()}\n",
    "    print(param_map)\n",
    "    \n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "    \n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d'% v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                node_name = '%s\\n %s' % (param_map.get(id(u)), size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "g = make_dot(model, model.state_dict())\n",
    "g.view()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
